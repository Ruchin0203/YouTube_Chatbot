# ğŸ¥ YouTube RAG QA System (LangChain + OpenAI)

This project implements a **Retrieval-Augmented Generation (RAG) pipeline** that allows you to **ask questions about a YouTube video** using its transcript. The system retrieves relevant transcript chunks and generates **grounded answers strictly from the video content**.

---

## âœ¨ What This Project Does

âœ… Fetches YouTube video transcripts
âœ… Splits long transcripts into chunks
âœ… Embeds transcript chunks using OpenAI embeddings
âœ… Stores embeddings in a FAISS vector database
âœ… Retrieves relevant chunks for a user query
âœ… Uses an LLM to answer questions **only from retrieved context**
âœ… Prevents hallucinations by enforcing context-only answers

---

## ğŸ§  Architecture Overview

```
YouTube Video
     â†“
Transcript Extraction
     â†“
Text Chunking
     â†“
Embedding Generation (OpenAI)
     â†“
FAISS Vector Store
     â†“
Similarity Retrieval
     â†“
Prompt Augmentation
     â†“
LLM Answer (GPT-4o-mini)
```

---

## ğŸ§± Tech Stack

### Core Libraries

* **LangChain**
* **OpenAI API**
* **FAISS (Vector Database)**
* **YouTube Transcript API**

### Models Used

* **Embeddings:** `text-embedding-3-small`
* **LLM:** `gpt-4o-mini`

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Install Dependencies

```bash
pip install youtube-transcript-api \
            langchain-community \
            langchain-openai \
            faiss-cpu \
            tiktoken \
            python-dotenv
```

---

### 2ï¸âƒ£ Set Environment Variables

âš ï¸ **DO NOT hardcode API keys in production**

```python
import os
os.environ["OPENAI_API_KEY"] = "your_openai_api_key_here"
```

Or using `.env` (recommended):

```env
OPENAI_API_KEY=your_openai_api_key_here
```

---

## ğŸš€ How It Works (Step-by-Step)

---

## ğŸ”¹ Step 1: Indexing (Document Ingestion)

### 1aï¸âƒ£ Fetch YouTube Transcript

```python
video_id = "Gfr50f6ZBvo"

transcript_list = YouTubeTranscriptApi.get_transcript(
    video_id,
    languages=["en"]
)

transcript = " ".join(chunk["text"] for chunk in transcript_list)
```

If captions are disabled, the app exits gracefully.

---

### 1bï¸âƒ£ Split Transcript into Chunks

```python
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)

chunks = splitter.create_documents([transcript])
```

âœ” Prevents context overflow
âœ” Maintains semantic continuity

---

### 1cï¸âƒ£ Generate Embeddings & Store in FAISS

```python
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

vector_store = FAISS.from_documents(chunks, embeddings)
```

FAISS enables **fast similarity search** over transcript chunks.

---

## ğŸ”¹ Step 2: Retrieval

```python
retriever = vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 4}
)
```

This retrieves the **top-k most relevant transcript chunks** for a question.

---

## ğŸ”¹ Step 3: Augmentation (Prompt Engineering)

The system **forces the LLM to answer only from retrieved context**.

```python
prompt = PromptTemplate(
    template="""
    You are a helpful assistant.
    Answer ONLY from the provided transcript context.
    If the context is insufficient, just say you don't know.

    {context}
    Question: {question}
    """,
    input_variables=["context", "question"]
)
```

ğŸš« No hallucinations
âœ… Context-grounded answers

---

## ğŸ”¹ Step 4: Generation (LLM)

```python
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.2
)
```

Low temperature ensures **fact-based, stable answers**.

---

## ğŸ”— Full RAG Chain (Production-Style)

```python
parallel_chain = RunnableParallel({
    "context": retriever | RunnableLambda(format_docs),
    "question": RunnablePassthrough()
})

main_chain = parallel_chain | prompt | llm | StrOutputParser()
```

---

### ğŸ§ª Example Queries

```python
main_chain.invoke("Who is Demis?")
```

```python
main_chain.invoke("Is nuclear fusion discussed in this video?")
```

```python
main_chain.invoke("Can you summarize the video?")
```

---

## ğŸ“Œ Key Design Decisions

* ğŸ”’ **Context-only answering** (no hallucination)
* âš¡ **FAISS for fast retrieval**
* ğŸ§  **OpenAI embeddings for semantic search**
* ğŸ” **Composable LangChain runnables**
* ğŸ“š **Chunk overlap to preserve meaning**

---

## ğŸ›¡ï¸ Safety & Best Practices

* Never commit API keys
* Use `.env` files
* Limit chunk size to avoid token overflow
* Keep `temperature â‰¤ 0.3` for QA tasks

---

## ğŸš€ Possible Extensions

* âœ… Streamlit / Flask UI
* âœ… Multi-video indexing
* âœ… Persistent FAISS storage
* âœ… Timestamped answers
* âœ… Source citation per answer
* âœ… Whisper fallback if transcripts are disabled

---

## ğŸ“„ License

MIT License â€” free to use and modify.

---

## ğŸŒŸ Summary

This project demonstrates a **clean, real-world RAG pipeline** that turns YouTube videos into **queryable knowledge bases**, suitable for:

* AI tutors
* Video summarization
* Research assistants
* Internal knowledge tools

---

### ğŸ§  Built with LangChain + OpenAI

**Ask videos questions. Get grounded answers.**
